{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T-cOk2SQleA"
      },
      "outputs": [],
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "\n",
        "num = 1\n",
        "# Load the input video\n",
        "video_path = f\"/content/drive/My Drive/{num}.mp4\"\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file was opened successfully\n",
        "if not video.isOpened():\n",
        "    print(\"Error reading video file\")\n",
        "    exit()\n",
        "\n",
        "# Get the frame width and height\n",
        "frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create a VideoWriter object to store the output video as MP4\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec for MP4 format\n",
        "output_video_path = f\"/content/drive/My Drive/retinafaceop{num}.mp4\"\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, 29, (frame_width, frame_height))\n",
        "\n",
        "# Get the frame rate of the video\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Process the video\n",
        "processed_frames = 0\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if ret:\n",
        "        # Perform face extraction using DeepFace\n",
        "        faces = DeepFace.extract_faces(frame, detector_backend='retinaface', enforce_detection=False)\n",
        "\n",
        "        # Draw bounding boxes around detected faces\n",
        "        for face in faces:\n",
        "            x, y, w, h = face[\"facial_area\"]['x'], face[\"facial_area\"]['y'], face[\"facial_area\"]['w'], face[\"facial_area\"]['h']\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        # Write the processed frame to the output video\n",
        "        output_video.write(frame)\n",
        "\n",
        "        # Increment the number of processed frames\n",
        "        processed_frames += 1\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Progress: {processed_frames}/{total_frames} frames processed\")\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release video capture and video writer objects\n",
        "video.release()\n",
        "output_video.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"\\nThe video was successfully processed and saved to:\", output_video_path)\n"
      ]
    }
  ]
}