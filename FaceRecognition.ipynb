{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RePSHL6MgPSz"
      },
      "outputs": [],
      "source": [
        "pip install deepface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##extracting unique faces"
      ],
      "metadata": {
        "id": "9k1XNBC-vyWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create a directory to store the extracted faces in Google Drive\n",
        "output_faces_dir = \"/content/drive/My Drive/extracted_faces1\"\n",
        "if os.path.exists(output_faces_dir):\n",
        "    shutil.rmtree(output_faces_dir)\n",
        "os.makedirs(output_faces_dir)\n",
        "\n",
        "# Initialize variables\n",
        "face_db = {}\n",
        "face_id = 1\n",
        "num = 9\n",
        "target_duration_secs = 15\n",
        "fps = 29\n",
        "\n",
        "# Load the input video\n",
        "video_path = f\"/content/drive/My Drive/{num}.mp4\"\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file was opened successfully\n",
        "if not video.isOpened():\n",
        "    print(\"Error reading video file\")\n",
        "    exit()\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the number of frames to process for the target duration\n",
        "target_frames = int(target_duration_secs * fps)\n",
        "\n",
        "# Process the video\n",
        "processed_frames = 0\n",
        "while processed_frames < target_frames:\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if ret:\n",
        "        # Perform face extraction using DeepFace\n",
        "        faces = DeepFace.extract_faces(frame, detector_backend='retinaface', enforce_detection=False)\n",
        "\n",
        "        # Extract and store unique faces\n",
        "        for face in faces:\n",
        "            x, y, w, h = face[\"facial_area\"]['x'], face[\"facial_area\"]['y'], face[\"facial_area\"]['w'], face[\"facial_area\"]['h']\n",
        "            extracted_face = frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Convert the extracted face to grayscale\n",
        "            gray_extracted_face = cv2.cvtColor(extracted_face, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Resize the extracted face to a fixed size for better comparison\n",
        "            resized_extracted_face = cv2.resize(gray_extracted_face, (100, 100))\n",
        "\n",
        "            # Initialize a flag to check if the extracted face is unique\n",
        "            unique_face = True\n",
        "\n",
        "            # Extract embeddings for the extracted face\n",
        "            extracted_face_embedding = DeepFace.represent(extracted_face, model_name='ArcFace', enforce_detection=False)\n",
        "\n",
        "            # Compare the extracted face with faces in the database\n",
        "            for fid, fdata in face_db.items():\n",
        "\n",
        "                # Extract the embedding from the dictionary\n",
        "                db_face_embedding_np = np.array(fdata[\"embedding\"])\n",
        "\n",
        "                # Calculate the cosine similarity between the embeddings\n",
        "                # similarity = np.dot(extracted_face_embedding[0][\"embedding\"], db_face_embedding_np[0][\"embedding\"]) / (np.linalg.norm(extracted_face_embedding[0][\"embedding\"]) * np.linalg.norm(db_face_embedding_np))\n",
        "                similarity = DeepFace.verify(extracted_face_embedding[0][\"embedding\"], db_face_embedding_np[0][\"embedding\"], model_name='ArcFace', distance_metric='cosine')\n",
        "\n",
        "                # Calculate the similarity between embeddings\n",
        "                similarity = similarity['distance']\n",
        "\n",
        "                if similarity < 0.5:\n",
        "                  unique_face = False\n",
        "                  face_id = fid\n",
        "                  break\n",
        "\n",
        "            # If the extracted face is unique, assign a new ID to it\n",
        "            if unique_face:\n",
        "                # Save the extracted face with a new ID\n",
        "                face_path = os.path.join(output_faces_dir, f\"face_{face_id}.jpg\")\n",
        "                cv2.imwrite(face_path, extracted_face)\n",
        "\n",
        "                # Update the face database\n",
        "                face_db[face_id] = {\"path\": face_path, \"embedding\": extracted_face_embedding}\n",
        "\n",
        "                # Increment the face ID\n",
        "                face_id += 1\n",
        "\n",
        "        # Increment the number of processed frames\n",
        "        processed_frames += 1\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Progress: {processed_frames}/{target_frames} frames processed\")\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release video capture\n",
        "video.release()\n",
        "\n",
        "# Print the face database\n",
        "print(\"\\nFace Database:\")\n",
        "for fid, fdata in face_db.items():\n",
        "    print(f\"Face ID: {fid}, Path: {fdata['path']}\")\n",
        "\n",
        "# Save the face database to a file in Google Drive\n",
        "face_db_path = \"/content/drive/My Drive/face_database1.txt\"\n",
        "with open(face_db_path, \"w\") as f:\n",
        "    for fid, fdata in face_db.items():\n",
        "        f.write(f\"Face ID: {fid}, Path: {fdata['path']}\\n\")\n",
        "\n",
        "print(\"\\nThe unique faces were successfully extracted and saved to:\", output_faces_dir)\n",
        "print(\"The face database was saved to:\", face_db_path)\n"
      ],
      "metadata": {
        "id": "ghVDcxOeq3ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recognizing faces using db"
      ],
      "metadata": {
        "id": "3Dt04bjHvuid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "\n",
        "# Load the face database from the file\n",
        "face_db_path = \"/content/drive/My Drive/face_database1.txt\"\n",
        "face_db = {}\n",
        "with open(face_db_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split(\", \")\n",
        "        face_id = int(parts[0].split(\": \")[1])\n",
        "        face_path = parts[1].split(\": \")[1]\n",
        "        face_db[face_id] = face_path\n",
        "\n",
        "# Load the input video\n",
        "video_path = \"/content/drive/My Drive/9.mp4\"\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video file was opened successfully\n",
        "if not video.isOpened():\n",
        "    print(\"Error reading video file\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Define the codec and create VideoWriter object for output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_video_path = \"/content/drive/My Drive/facerecogtry.mp4\"\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Initialize variables for frame processing\n",
        "target_duration_secs = 3\n",
        "target_frames = int(target_duration_secs * fps)\n",
        "processed_frames = 0\n",
        "\n",
        "# Process the video frame by frame\n",
        "while processed_frames < target_frames:\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform face detection on the frame\n",
        "    faces = DeepFace.extract_faces(frame, detector_backend='retinaface', enforce_detection=False)\n",
        "\n",
        "    # Recognize faces and draw bounding boxes\n",
        "    for face in faces:\n",
        "        x, y, w, h = face[\"facial_area\"]['x'], face[\"facial_area\"]['y'], face[\"facial_area\"]['w'], face[\"facial_area\"]['h']\n",
        "        extracted_face = frame[y:y+h, x:x+w]\n",
        "\n",
        "        # Extract embeddings for the extracted face\n",
        "        # extracted_face_embedding = DeepFace.represent(extracted_face, model_name='ArcFace', enforce_detection=False)\n",
        "\n",
        "        # Compare the extracted face with faces in the database\n",
        "        recognized = False\n",
        "        for face_id, face_path in face_db.items():\n",
        "            # Load the reference face\n",
        "            reference_face = cv2.imread(face_path)\n",
        "\n",
        "            # Extract embeddings for the reference face\n",
        "            # reference_face_embedding = DeepFace.represent(reference_face, model_name='ArcFace', enforce_detection=False)\n",
        "\n",
        "            # Compare the embeddings\n",
        "            similarity = DeepFace.verify(extracted_face, reference_face, model_name='ArcFace', distance_metric='cosine')\n",
        "            similarity = similarity['distance']\n",
        "\n",
        "            # If the similarity is above a threshold, consider the face recognized\n",
        "            if similarity < 0.5:  # Adjust the threshold as needed\n",
        "                recognized = True\n",
        "                break\n",
        "\n",
        "        # Draw bounding box around the recognized face\n",
        "        if recognized:\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Face ID: {face_id}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    output_video.write(frame)\n",
        "    processed_frames += 1\n",
        "    print(f\"Processed frame {processed_frames}/{target_frames}\")\n",
        "\n",
        "# Release video capture and close windows\n",
        "video.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "AuG0Bt3LgQx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnF-F_01SNfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}